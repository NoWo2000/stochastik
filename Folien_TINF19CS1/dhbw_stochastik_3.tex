\documentclass{beamer}
\usetheme{Warsaw}

\usepackage[utf8]{inputenc}
\usepackage{fancybox}
\usepackage{multimedia} 
\usepackage{subfig}
\usepackage{amsmath}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,     
    urlcolor=blue
}
\usepackage[all]{xy}
\begin{document}


\title[Stochastik] % (optional, only for long titles)
{Stochastik für Informatiker
\\
\includegraphics[scale=0.5]{img/craps}
}
\subtitle{}
\author[Dr. Johannes Riesterer] % (optional, for multiple authors)
{Dr.  rer. nat. Johannes Riesterer}

\date[KPT 2004] % (optional)
{}

\subject{Stochastik}


\frame{\titlepage}


\begin{frame}
    \frametitle{Zufallsvariablen}
\framesubtitle{}

\begin{block}{Messraum}
Ein Messraum ist ein Paar $(\Omega, \mathcal{A})$ bestehend aus einer Menge $\Omega$ und einer Sigma-Algebra $\mathcal{A} \subset \mathcal{P}(\Omega)$.
\end{block}

\begin{block}{Zufallsvariablen}
Sei $(\Omega, \mathcal{A}, P)$ ein Wahrscheinlichkeitsraum und $(\Omega', \mathcal{A}')$ ein Messraum. Eine Zufallsvariable ist eine Abbildung
$$X : \Omega \to \Omega'$$ 
so dass für alle Ereignisse $A' \in  \mathcal{A}'$
$$ X^{-1} (A') \in \mathcal{A}$$
 ein Ereignis in $\mathcal{A}$ ist. Urbilder von Ereignissen sind also Ereignisse.
\end{block}

 \end{frame}

\begin{frame}
    \frametitle{Zufallsvariablen}
\framesubtitle{}
\begin{block}{Beispiel (Münzwurf)}
$\Omega = \{\text{Kopf}, \text{Zahl} \} $, $\Omega' = \{ 0,1 \}$  mit jeweils Potenzmenge als Sigma-Algebra und 
\begin{align*}
& X (\text{Kopf} ) = 0 \\
& X (\text{Zahl} ) = 1 
\end{align*}
\end{block}

\begin{block}{Beispiel (Summe zweier Würfel)}
$\Omega = \{1,2,3,4,5,6 \} \times \{1,2,3,4,5,6 \} $, $\Omega' = \{ 2,3,4,5,6,7,8,9,10, 11, 12\}$   mit jeweils Potenzmenge als Sigma-Algebra und $X: \Omega \to \Omega'; X (a,b) := a +b$. 
\end{block}

 \end{frame}

\begin{frame}
    \frametitle{Zufallsvariablen}
\framesubtitle{}
\begin{block}{Bildmaß}
Sei $(\Omega, \mathcal{A}, P)$ ein Wahrscheinlichkeitsraum, $(\Omega', \mathcal{A}')$ ein Messraum und  $X : \Omega \to \Omega'$  Eine Zufallsvariable. 
Durch 
\begin{align*}
P_X (A') := P(X^{-1} (A'))
\end{align*}
 für $A' \in \mathcal{A}'$ wird ein Wahrscheinlichkeitsmaß auf  $(\Omega', \mathcal{A}')$ definiert. Es wird Bildmaß genannt. Anstelle von $P_X (A')$ wird auch die Schreibweise $P (X \in A'):= P_X (A')$ verwendet.
\end{block}


 \end{frame}

\begin{frame}
    \frametitle{Zufallsvariablen}
\framesubtitle{}

\begin{block}{Beispiel (Summe zweier Würfel)}
$\Omega = \{1,2,3,4,5,6 \} \times \{1,2,3,4,5,6 \} $, $\Omega' = \{ 2,3,4,5,6,7,8,9,10, 11, 12\}$ und $X: \Omega \to \Omega'; X (a,b) := a +b$. Dann ist 
$P_X(3) = P(\{(1,2), (2,1)\}) = \frac{2}{36} = \frac{1}{18}$ 
\end{block}

 \end{frame}




\begin{frame}
    \frametitle{Integration bezüglich eines Wahrscheinlichkeitsmaßes}
\framesubtitle{}

\begin{block}{Indikatorfunktion}
Für eine Teilmenge $A \in \mathcal{A}$ heißt
$$ 1_A (x): = \begin{cases} 1 \text{  falls }   x \in A  \\  0  \text{  sonst}  \end{cases}$$
Indikatorfunktion.
\end{block}

\begin{block}{}
Eine Funktion 
$$ \varphi(x) := \sum_{k=1}^m c_k 1_{A_k}(x)$$ mit $c_k \in \mathbb{R}$ und $A_k \in \mathcal{A}$ mit $A_i \cap A_j = \emptyset$ für $i \neq j$
heißt Treppenfunktion.
\end{block}

 \end{frame}


\begin{frame}
    \frametitle{Integration bezüglich eines Wahrscheinlichkeitsmaßes}
\framesubtitle{}

\begin{block}{Hüllreihe}
Eine Hüllreihe zu einer Funktion $f :\Omega \to \mathbb{R}$ ist eine Reihe $\phi(x):= \sum_{k=1}^{\infty} c_k  1_{A_k} (x)$ mit den folgenden Eigenschaften:
\begin{itemize}
\item $c_k \in \mathbb{R}$ sind positive reelle Zahlen $c_k >0$.
\item $A_k \in \mathcal{A}$.
\item Für alle $x \in \Omega$ gilt $|f(x) | \leq \phi(x)$.
\end{itemize}
\end{block}

 \end{frame}



\begin{frame}
    \frametitle{Integration bezüglich eines Wahrscheinlichkeitsmaßes}
\framesubtitle{}

\begin{block}{}
Für eine Treppenfunktion $ \varphi(x) := \sum_{k=1}^m c_k 1_{A_k}(x)$ definieren wir das Integral durch
$$\int_{\Omega} \varphi dP := \sum_{k =1}^m  c_k P(A_k) \; . $$
\end{block}


\begin{block}{}
Der Inhalt einer Hüllreihe $\phi(x):= \sum_{k=1}^{\infty} c_k  1_{A_k} (x)$ ist definiert durch 
$$I_P (\phi) := \sum_{k=1}^{\infty} c_k \;  P(A_k) \; .$$
\end{block}

 \end{frame}




\begin{frame}
    \frametitle{Integration bezüglich eines Wahrscheinlichkeitsmaßes}
\framesubtitle{}

\begin{block}{}
Die $L_{P^1}$-Halbnorm einer Funktion $f : \Omega\to \mathbb{R}$ ist definiert durch das Infimum der Inhalte der Hüllreihen zu $f$
$$ || f ||_{P^1} : = \inf  \biggl \{   I(\phi) \; | \; \phi  \text{ ist Hüllreihe zu  }  f \biggr \} \; .$$
\end{block}

\begin{block}{}
Eine Funktion $f : \Omega \to \mathbb{R}$ heißt integrierbar, falls eine Folge von Treppenfunktionen  $\varphi_k$ existiert mit
$$ || f -  \varphi_k ||_{P^1} \to 0 \text{ für } k \to \infty \;. $$
In diesem Fall heißt
$$ \int_{\Omega} f(x) dP := \lim_{k \to \infty}  \int_{\Omega}  \varphi_k  dP$$
das Integral von $f$ über $\Omega$.
\end{block}

 \end{frame}



\begin{frame}
    \frametitle{Integration bezüglich eines Wahrscheinlichkeitsmaßes}
\framesubtitle{}

\begin{block}{Neuer Wein in alten Schläuchen}
Integration bezüglich eines Wahrscheinlichkeitsmaßes verhält sich analog zu Lebesguemaß von letztem Semester.
\end{block}

 \end{frame}


\begin{frame}
    \frametitle{Reelle Zufallsvariablen}
\framesubtitle{}

\begin{block}{}
Eine Menge $U \subset  \mathbb{R}^n$ heißt offen, falls für jeden Punkt $x \in U$ ein Radius $\epsilon > 0$ existiert, so dass der Ball $B_\epsilon (x)$ in $U$ enthalten ist, also 
$B_\epsilon (x) \subset U$ gilt.
\end{block}

\begin{figure}[htp]
      \centering
    \includegraphics[width=0.45\textwidth]{img/openset}
      \caption{Quelle: Wikipedia}
\end{figure}


 \end{frame}


\begin{frame}
    \frametitle{Zufallsvariablen}
\framesubtitle{}

\begin{block}{Borel'sche Sigma-Algebra}
Die Borel'sche   $\sigma$-Algebra $\mathcal{B}(\mathbb{R}^n)$über $\mathbb{R}^n$ ist die kleinste  $\sigma$-Algebra, die alle offenen Mengen $\mathcal{U}$ enthält, also 
\begin{align*}
A_\sigma (\mathcal{U}) := \bigcap \{  \mathcal{A} \subset \mathcal{P}(\mathbb{R}^n);  \;   \mathcal{U}  \subset  \mathcal{A},  \;  \mathcal{A} \text{ ist $\sigma$-Algebra} \}
\end{align*}
\end{block}

\begin{block}{Existenz}
Die Borel'sche   $\sigma$-Algebra existiert, da die Potenzmenge eine   $\sigma$-Algebra ist.
\end{block}

\begin{block}{Messbarkeit}
Die Borel'sche   $\sigma$-Algebra ist in der $\sigma$-Algebra der Lebesgue messbaren Mengen enthalten.
\end{block}
 \end{frame}





\begin{frame}
    \frametitle{Zufallsvariablen}
\framesubtitle{}

\begin{block}{Reelle Zufallsvariablen}
Unter einer reellen Zufallsvariable verstehen wir eine Zufallsvariable 
\begin{align*}
& X : \Omega \to \mathbb{R}^n \\
& X(\omega) := \biggl(X_1(\omega), \cdots , X_n(\omega)  \biggr) \; ,
\end{align*}
wobei $(\Omega, \mathcal{A}, P)$ ein Wahrscheinlichkeitsraum ist und $(\mathbb{R}^n, \mathcal{B}(\mathbb{R}^n))$ der $\mathbb{R}^n$ zusammen mit der Borel'schen Sigma-Algebra ist. Das Integral ist komponentenweise definiert durch
\begin{align*} 
\int_{\Omega} X dP :=  \biggl( \int_{\Omega} X_1 dP, \cdots , \int_{\Omega} X_n dP    \biggr)
\end{align*}

\end{block}

 \end{frame}

\begin{frame}
    \frametitle{Zufallsvariablen}
\framesubtitle{}

\begin{block}{Verteilungsfunktion}
Für eine reelle Zufallsvariable heißt 
\begin{align*} 
& F_X : \Omega \to [0,1] \\
& F_X (x) := P (X \leq x) := P_X (( -\infty, x )) = P(X^{-1} (-\infty, x))
\end{align*}
Verteilungsfunktion von $X$.
\end{block}
 \end{frame}

\begin{frame}
    \frametitle{Zufallsvariablen}
\framesubtitle{}

\begin{block}{Dichte}
Sei $\Omega \subset \mathbb{R}^n$ und $(\Omega, \mathcal{A})$ ein Messraum, wobei alle $A \in \mathcal{A}$ Lebesgue-messbar sind.
 Eine Funktion $f: \Omega \to \mathbb{R}$ heißt Dichte, falls für ihr Lebesgue-Integral $\int_{\Omega} f d \mu = 1$ gilt.
\end{block}
 \end{frame}

\begin{frame}
    \frametitle{Zufallsvariablen}
\framesubtitle{}
\begin{block}{Beispiel}
Die Funktion $f(x) = \frac{1}{\sqrt{\pi}} e^{- x^2}$ ist eine Dichte auf $ \mathbb{R}$.
\begin{align*}
& I := \int_{0}^{\infty} e^{-x^2} \; dx\\
& I^2 = \int_{0}^{\infty} \int_{0}^{\infty} e^{-(x^2+y^2)} \; dx \;dy \\
&x=r \cos \varphi ,y=r\sin \varphi ,r^2 = x^2 + y^2  \; (\text{ da } \cos^2 + \sin^2 = 1)\\
 &\text{ \href{https://de.wikipedia.org/wiki/Polarkoordinaten\#Zylinderkoordinaten}{LINK: Polarkoordinatentransformation}} \\
& = \int_{0}^{\frac{\pi}{2}}  \int_{0}^{\infty}r \cdot e^{-r^2} \; dr \;d\varphi \\
&= \frac{\pi}{2} \int_{0}^{\infty}r \cdot e^{-r^2} \; dr \\
&= -\frac{\pi}{4} [e^{-r^2} ]_0^{\infty} = \frac{\pi}{4} \Rightarrow I = \frac{\sqrt{\pi}}{2}
\end{align*}
\end{block}
 \end{frame}


\begin{frame}
    \frametitle{Zufallsvariablen}
\framesubtitle{}
\begin{block}{Beispiel}
Analog beweist man, dass für alle  $\mu \in \mathbb{R}, \sigma > 0 $ die Funktion $ f(x):=  \frac 1{\sigma \sqrt{2\pi}}e^{- \frac {1}{2} (\frac{x- \mu}{ \sigma})^2}$  eine  Dichte auf $ \mathbb{R}$ ist.
\end{block}
\begin{figure}[htp]
      \centering
    \includegraphics[width=0.76\textwidth]{img/normal}
      \caption{Quelle: Wikipedia}
\end{figure}
 \end{frame}

\begin{frame}
    \frametitle{Zufallsvariablen}
\framesubtitle{}
\begin{block}{Normalverteilung}
Eine reelle Zufallsvariable $X: \Omega \to \mathbb{R}$ heißt normalverteilt, wenn 
$F_X (x) = \int_{- \infty}^{x}  \frac 1{\sigma \sqrt{2\pi}}e^{- \frac {1}{2} (\frac{x- \mu}{ \sigma})^2}dx$ mit  $\mu \in \mathbb{R}, \sigma > 0 $ gilt. Man schreibt auch $X \sim \mathcal{N}(\mu, \sigma^2)$.
\end{block}
\begin{figure}[htp]
      \centering
    \includegraphics[width=0.76\textwidth]{img/normaldist}
      \caption{Quelle: Wikipedia}
\end{figure}
 \end{frame}



\begin{frame}
    \frametitle{Zufallsvariablen}
\framesubtitle{}
\begin{block}{Verteilung und Unabhängigkeit}
Sei $(\Omega, \mathcal{A}, P)$ ein Wahrscheinlichkeitsraum, $(R, \mathcal{B})$ ein Messraum  und
 $\{X_i\}_{i=1}^n$ ein Folge von Zufallsvariablen   $X_i :  \Omega \to R$.
Die Zufallsvariablen heißen identisch verteilt, falls
 $P_{X_i} = P_{X_j}$ für alle $i,j$  und
stochastisch unabhängig, falls
 $P_{(X_1, \cdots ,X_n)} = \prod_{i=1}^n P_{X_i}$ gilt. 
\end{block}
 \end{frame}

\end{document}
